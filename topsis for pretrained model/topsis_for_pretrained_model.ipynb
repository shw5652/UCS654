{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d019af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepface 0.0.79 requires Flask>=1.1.2, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "     ------------------------------------ 129.4/129.4 kB 401.1 kB/s eta 0:00:00\n",
      "Collecting dataset\n",
      "  Downloading dataset-1.6.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (21.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "     -------------------------------------- 42.0/42.0 kB 225.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.1-cp39-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.2-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     -------------------------------------- 57.6/57.6 kB 303.6 kB/s eta 0:00:00\n",
      "Collecting sqlalchemy<2.0.0,>=1.3.2 (from dataset)\n",
      "  Downloading SQLAlchemy-1.4.51-cp39-cp39-win_amd64.whl.metadata (10 kB)\n",
      "Collecting alembic>=0.6.2 (from dataset)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting banal>=1.0.1 (from dataset)\n",
      "  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
      "Collecting Mako (from alembic>=0.6.2->dataset)\n",
      "  Downloading Mako-1.3.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\shweta\\appdata\\roaming\\python\\python39\\site-packages (from alembic>=0.6.2->dataset) (4.1.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<2.0.0,>=1.3.2->dataset)\n",
      "  Downloading greenlet-3.0.3-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Mako->alembic>=0.6.2->dataset) (2.1.2)\n",
      "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "   ---------------------------------------- 8.4/8.4 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading dataset-1.6.2-py2.py3-none-any.whl (18 kB)\n",
      "Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 233.4/233.4 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "   ---------------------------------------- 330.1/330.1 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "   ---------------------------------------- 152.8/152.8 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading regex-2023.12.25-cp39-cp39-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 269.5/269.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.2-cp39-none-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 269.7/269.7 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-1.4.51-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 2.2/2.2 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 78.3/78.3 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "   ---------------------------------------- 169.0/169.0 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp39-cp39-win_amd64.whl (290 kB)\n",
      "   ---------------------------------------- 290.8/290.8 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 78.7/78.7 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: banal, tqdm, safetensors, regex, pyyaml, Mako, greenlet, fsspec, filelock, sqlalchemy, huggingface-hub, tokenizers, alembic, transformers, dataset\n",
      "Successfully installed Mako-1.3.2 alembic-1.13.1 banal-1.0.6 dataset-1.6.2 filelock-3.13.1 fsspec-2023.12.2 greenlet-3.0.3 huggingface-hub-0.20.3 pyyaml-6.0.1 regex-2023.12.25 safetensors-0.4.2 sqlalchemy-1.4.51 tokenizers-0.15.1 tqdm-4.66.1 transformers-4.37.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8111fae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.22.4)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Downloading pyarrow-15.0.0-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\shweta\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.66.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl.metadata (32 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shweta\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "   ---------------------------------------- 507.1/507.1 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 166.4/166.4 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.3-cp39-cp39-win_amd64.whl (366 kB)\n",
      "   ---------------------------------------- 366.0/366.0 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading pyarrow-15.0.0-cp39-cp39-win_amd64.whl (24.9 MB)\n",
      "   ---------------------------------------- 24.9/24.9 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.15-py39-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 133.3/133.3 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "   ---------------------------------------- 115.3/115.3 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp39-cp39-win_amd64.whl (29 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 50.7/50.7 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 76.9/76.9 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.12.2\n",
      "    Uninstalling fsspec-2023.12.2:\n",
      "      Successfully uninstalled fsspec-2023.12.2\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.4\n",
      "    Uninstalling dill-0.3.4:\n",
      "      Successfully uninstalled dill-0.3.4\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.16.1 dill-0.3.7 frozenlist-1.4.1 fsspec-2023.10.0 multidict-6.0.5 multiprocess-0.70.15 pyarrow-15.0.0 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02efb147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a591100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|████████████████████████████████████████████████████████████████████| 629/629 [00:00<00:00, 39.5kB/s]\n",
      "c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shweta\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|████████████████████████████████████████████████████████████| 268M/268M [01:03<00:00, 4.19MB/s]\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "tokenizer_config.json: 100%|████████████████████████████████████████████████████████████████| 48.0/48.0 [00:00<?, ?B/s]\n",
      "vocab.txt: 100%|█████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 472kB/s]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec84f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading torch-2.2.0-cp39-cp39-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.13.1)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 5.7/5.7 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.0.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.2/536.2 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading torch-2.2.0-cp39-cp39-win_amd64.whl (198.5 MB)\n",
      "   -------------------------------------- 198.5/198.5 MB 794.9 kB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.1.1\n",
      "    Uninstalling typing_extensions-4.1.1:\n",
      "      Successfully uninstalled typing_extensions-4.1.1\n",
      "Successfully installed mpmath-1.3.0 networkx-3.2.1 sympy-1.12 torch-2.2.0 typing-extensions-4.9.0\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e019753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ea40004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5330e47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|███████████████████████████████████████████████████████████| 18.6M/18.6M [00:08<00:00, 2.08MB/s]\n",
      "Downloading data: 100%|███████████████████████████████████████████████████████████| 1.23M/1.23M [00:00<00:00, 1.78MB/s]\n",
      "Generating train split: 100%|███████████████████████████████████████| 120000/120000 [00:00<00:00, 277787.49 examples/s]\n",
      "Generating test split: 100%|████████████████████████████████████████████| 7600/7600 [00:00<00:00, 237320.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bf4ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|████████████████████████████████████████████████████████████████████████████| 805/805 [00:00<?, ?B/s]\n",
      "c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shweta\\.cache\\huggingface\\hub\\models--wesleyacheng--news-topic-classification-with-bert. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|████████████████████████████████████████████████████████████| 268M/268M [01:31<00:00, 2.92MB/s]\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████████████████████████████████████████████████████| 320/320 [00:00<00:00, 20.0kB/s]\n",
      "vocab.txt: 100%|█████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 555kB/s]\n",
      "tokenizer.json: 100%|███████████████████████████████████████████████████████████████| 711k/711k [00:00<00:00, 2.14MB/s]\n",
      "special_tokens_map.json: 100%|████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 15.6kB/s]\n"
     ]
    }
   ],
   "source": [
    "m1 = pipeline(\"text-classification\", model=\"wesleyacheng/news-topic-classification-with-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "835804f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|████████████████████████████████████████████████████████████████████████████| 847/847 [00:00<?, ?B/s]\n",
      "c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shweta\\.cache\\huggingface\\hub\\models--mrm8488--bert-mini-finetuned-age_news-classification. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|██████████████████████████████████████████████████████████| 44.7M/44.7M [00:14<00:00, 3.05MB/s]\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████| 324/324 [00:00<?, ?B/s]\n",
      "vocab.txt: 100%|█████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 663kB/s]\n",
      "special_tokens_map.json: 100%|█████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 107kB/s]\n"
     ]
    }
   ],
   "source": [
    "m2 = pipeline(\"text-classification\", model=\"mrm8488/bert-mini-finetuned-age_news-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97b3c7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|█████████████████████████████████████████████████████████████████████| 805/805 [00:00<00:00, 100kB/s]\n",
      "c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shweta\\.cache\\huggingface\\hub\\models--JohnHwang--news_classification. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model JohnHwang/news_classification with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification'>). See the original errors:\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 278, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2833, in from_pretrained\n    raise EnvironmentError(\nOSError: JohnHwang/news_classification does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\nwhile loading with TFDistilBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 278, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2833, in from_pretrained\n    raise EnvironmentError(\nOSError: JohnHwang/news_classification does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16088/684241641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text-classification\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"JohnHwang/news_classification\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mmodel_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m         framework, model = infer_framework_load_model(\n\u001b[0m\u001b[0;32m    871\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m             \u001b[0mmodel_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_traceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0merror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf\"while loading with {class_name}, an error is thrown:\\n{trace}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    292\u001b[0m                 \u001b[1;34mf\"Could not load model {model} with any of the following classes: {class_tuple}. See the original errors:\\n\\n{error}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not load model JohnHwang/news_classification with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification'>). See the original errors:\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 278, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2833, in from_pretrained\n    raise EnvironmentError(\nOSError: JohnHwang/news_classification does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\nwhile loading with TFDistilBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 278, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2833, in from_pretrained\n    raise EnvironmentError(\nOSError: JohnHwang/news_classification does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\n\n"
     ]
    }
   ],
   "source": [
    "m3 = pipeline(\"text-classification\", model=\"JohnHwang/news_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8357e27b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not load model fabriceyhc/bert-base-uncased-ag_news with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'>). See the original errors:\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 278, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2833, in from_pretrained\n    raise EnvironmentError(\nOSError: fabriceyhc/bert-base-uncased-ag_news does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\nwhile loading with TFBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 278, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2833, in from_pretrained\n    raise EnvironmentError(\nOSError: fabriceyhc/bert-base-uncased-ag_news does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16088/1153588976.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text-classification\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fabriceyhc/bert-base-uncased-ag_news\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_pt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mmodel_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m         framework, model = infer_framework_load_model(\n\u001b[0m\u001b[0;32m    871\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m             \u001b[0mmodel_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_traceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0merror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf\"while loading with {class_name}, an error is thrown:\\n{trace}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    292\u001b[0m                 \u001b[1;34mf\"Could not load model {model} with any of the following classes: {class_tuple}. See the original errors:\\n\\n{error}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not load model fabriceyhc/bert-base-uncased-ag_news with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'>). See the original errors:\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 278, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2833, in from_pretrained\n    raise EnvironmentError(\nOSError: fabriceyhc/bert-base-uncased-ag_news does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\nwhile loading with TFBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 278, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2833, in from_pretrained\n    raise EnvironmentError(\nOSError: fabriceyhc/bert-base-uncased-ag_news does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\n\n"
     ]
    }
   ],
   "source": [
    "m4 = pipeline(\"text-classification\", model=\"fabriceyhc/bert-base-uncased-ag_news\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a574437a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|████████████████████████████████████████████████████████████████████| 766/766 [00:00<00:00, 95.2kB/s]\n",
      "c:\\users\\shweta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shweta\\.cache\\huggingface\\hub\\models--joeddav--distilbert-base-uncased-agnews-student. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "tf_model.h5: 100%|██████████████████████████████████████████████████████████████████| 268M/268M [01:25<00:00, 3.13MB/s]\n",
      "Some layers from the model checkpoint at joeddav/distilbert-base-uncased-agnews-student were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at joeddav/distilbert-base-uncased-agnews-student and are newly initialized: ['dropout_73']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████| 258/258 [00:00<?, ?B/s]\n",
      "vocab.txt: 100%|█████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 646kB/s]\n",
      "special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████| 112/112 [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "m5 = pipeline(\"text-classification\", model=\"joeddav/distilbert-base-uncased-agnews-student\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42652d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
